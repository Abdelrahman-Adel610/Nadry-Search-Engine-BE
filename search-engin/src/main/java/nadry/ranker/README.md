# TF-IDF and Cosine Similarity Overview

This document provides a summary of the core formulas used in TF-IDF-based text retrieval and ranking systems.

---

## ðŸ“˜ 1. Term Frequency (TF)
**Definition:** How often a term appears in a document.

```
TF(t, d) = (Number of times term t appears in document d) / (Total number of terms in d)
```

---

## ðŸ“— 2. Inverse Document Frequency (IDF)
**Definition:** How unique or rare a term is across all documents.

```
IDF(t) = log(N / (1 + DF(t)))
```
- **N**: Total number of documents
- **DF(t)**: Number of documents containing term *t*

---

## ðŸ“™ 3. TF-IDF
**Definition:** Importance of a term in a specific document relative to the entire corpus.

```
TF-IDF(t, d) = TF(t, d) * IDF(t)
```

---

## ðŸ“• 4. Cosine Similarity
**Definition:** Measures similarity between query vector **Q** and document vector **D**.

```
cos(Î¸) = (Q â€¢ D) / (||Q|| * ||D||)
       = sum(Q_i * D_i) / (sqrt(sum(Q_i^2)) * sqrt(sum(D_i^2)))
```

- **Q â€¢ D**: Dot product of query and document vectors
- **||Q||**, **||D||**: Magnitudes (Euclidean norm) of Q and D

---

## Usage
These formulas are used to:
1. Convert documents and queries into numerical vectors.
2. Measure how similar documents are to a given search query.
3. Rank documents by similarity scores.

---

*Generated by ChatGPT*