package webCrawler;

import java.io.*;
import java.net.MalformedURLException;
import java.net.URI;
import java.net.URISyntaxException;
import java.net.URL;
import java.nio.charset.StandardCharsets;
import java.nio.file.Files;
import java.nio.file.InvalidPathException;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.Collections; // Import Collections
import java.util.LinkedList;
import java.util.List;
import java.util.concurrent.atomic.AtomicBoolean; // For shutdown signal
import java.util.regex.Pattern;

import org.jsoup.Connection;
import org.jsoup.Jsoup;
import org.jsoup.nodes.*;
import org.jsoup.select.Elements;

public class WebCrawler implements Runnable {

    // --- Constants and Shared Static Resources ---
    private static final Pattern INVALID_FILENAME_CHARS = Pattern.compile("[\\\\/:*?\"<>|]");
    private static final int MAX_PAGES_NUMBER = 100; // Or get from config
    private static final Path BASE_STORAGE_PATH = Paths.get("D:\\faculty stuff\\2nd year\\2nd term\\projects\\Ndry search engin\\search-engin\\crawled_html");
    private static final String MY_USER_AGENT = "Ndry/1.0"; // Use your agent name

    // Thread-safe lists for results (accessible after crawl finishes)
    public static final List<Path> paths = Collections.synchronizedList(new LinkedList<>());
    public static final List<String> links = Collections.synchronizedList(new LinkedList<>());

    // Shared shutdown signal (set by main thread)
    private static final AtomicBoolean shutdownSignal = new AtomicBoolean(false);

    // --- Instance Variables ---
    private final MongoJava database; // Shared DB access instance

    // Constructor: Pass shared resources
    public WebCrawler(MongoJava db) {
        this.database = db;
    }

    // Static method for main thread to signal shutdown
    public static void signalShutdown() {
        shutdownSignal.set(true);
        // No explicit notify needed here if workers check the flag regularly
    }

    @Override
    public void run() {
        System.out.println("Worker thread started: " + Thread.currentThread().getName());
        // RobotChecker can be static IF its methods are thread-safe (check its implementation)
        // RobotChecker robotChecker = new RobotChecker(); // Or instantiate if needed

        try {
            // Main loop: continues as long as shutdown is not signaled
            while (!shutdownSignal.get() && !Thread.currentThread().isInterrupted()) {

                // 1. Dequeue URL from Database
                String currentUrl = database.dequeueUrl();

                if (currentUrl == null) {
                    // Queue is likely empty, pause and retry unless shutdown signaled
                    if (shutdownSignal.get()) break; // Exit if shutdown signaled while polling
                    try {
                        // System.out.println(Thread.currentThread().getName() + " - Queue empty, pausing...");
                        Thread.sleep(1500); // Wait 1.5 seconds before checking queue again
                    } catch (InterruptedException e) {
                        Thread.currentThread().interrupt(); // Restore interrupt status
                        System.out.println(Thread.currentThread().getName() + " interrupted while sleeping.");
                        break; // Exit loop if interrupted
                    }
                    continue; // Go back to the start of the while loop
                }

                // --- Process the dequeued URL ---
                // System.out.println(Thread.currentThread().getName() + " Processing: " + currentUrl);

                // 2. Robot Check (Make sure RobotChecker.isUrlAllowed is thread-safe)
                if (!RobotChecker.isUrlAllowed(currentUrl)) {
                    // System.out.println(Thread.currentThread().getName() + " -> Robots.txt DISALLOWED");
                    // Optional: Mark as visited to prevent re-queue/re-check?
                    // database.markVisited(currentUrl);
                    continue;
                }

                // 3. Visited Check (Database check is crucial)
                if (database.isVisited(currentUrl)) {
                    // System.out.println(Thread.currentThread().getName() + " -> Already visited (DB check).");
                    continue;
                }

                // 4. Fetch Document
                Document doc = getDocument(currentUrl); // Use static helper method
                if (doc == null) {
                    // Fetch error occurred (logged in getDocument)
                    // Don't mark visited, allow potential retry if it gets re-queued later
                    continue;
                }

                // --- Page processing starts ONLY after successful fetch ---

                // 5. Mark as Visited *NOW*
                database.markVisited(currentUrl);

                // 6. Signature Check
                String cs = calculateCompactString(doc);
                if (cs == null) {
                     System.err.println(Thread.currentThread().getName() + " -> Could not calculate signature for: " + currentUrl);
                     continue;
                }
                if (database.hasCompactString(cs)) {
                    // System.out.println(Thread.currentThread().getName() + " -> Skipping duplicate content signature.");
                    continue;
                }
                database.addCompactString(cs);

                // 7. Save HTML Document
                Path savedFilePath = null; // Store the path if saving succeeds
                try {
                    savedFilePath = saveHtmlDocument(currentUrl, doc); // Use static helper
                } catch (Exception e) {
                     System.err.println(Thread.currentThread().getName() + " -> FAILED to save HTML for " + currentUrl + ": " + e.getMessage());
                     // Continue processing links even if saving fails?
                }

                // 8. Increment Counter and Check Limit (using DB atomic operation)
                long currentGlobalCount = database.incrementAndGetCrawledCount();
                if (currentGlobalCount == -1) {
                     System.err.println(Thread.currentThread().getName() + " - Failed to increment page count! Stopping worker.");
                     break; // Stop this worker on DB error
                }

                System.out.println(Thread.currentThread().getName() + " -> Processed (" + currentGlobalCount + "): " + currentUrl);

                 // Add to results lists (AFTER potential errors/skips, and if saved ok)
                 if (savedFilePath != null) {
                    // These adds are thread-safe due to synchronizedList wrapper
                    links.add(currentUrl);
                    paths.add(savedFilePath);
                 }

                // Check limit AFTER successful processing and incrementing
                if (currentGlobalCount >= MAX_PAGES_NUMBER) {
                    System.out.println(Thread.currentThread().getName() + " -> Reached page limit (" + currentGlobalCount + ")! Signaling shutdown.");
                    signalShutdown(); // Signal all threads to stop
                    break; // Exit this worker's loop
                }

                // 9. Extract and Enqueue Links
                Elements linksElements = doc.select("a[href]");
                for (Element link : linksElements) {
                    String nextUrlRaw = link.absUrl("href");
                    if (nextUrlRaw == null || nextUrlRaw.isEmpty() ||
                        !(nextUrlRaw.toLowerCase().startsWith("http://") || nextUrlRaw.toLowerCase().startsWith("https://")))
                    {
                        continue; // Skip non-HTTP link
                    }

                    try {
                        // Normalize BEFORE checking/enqueueing
                        String nextUrlNormalized = normalizeLink(nextUrlRaw);

                        // Check visited using DATABASE before enqueueing
                        if (!database.isVisited(nextUrlNormalized)) {
                             database.enqueueUrl(nextUrlNormalized); // Enqueue the new valid URL
                             // No notify needed here - workers poll the queue
                        }
                    } catch (URISyntaxException | MalformedURLException | IllegalArgumentException e) {
                         // Log normalization errors quietly or ignore
                         // System.err.println("   Skipping malformed link: " + nextUrlRaw + " (" + e.getMessage() + ")");
                    } catch (Exception e) {
                        System.err.println(Thread.currentThread().getName() + " -> Error processing link '" + nextUrlRaw + "': " + e.getMessage());
                    }
                } // End link extraction loop

            } // End main while loop
        } catch (Exception e) {
            // Catch unexpected errors within a worker thread's main loop
            System.err.println("!!! UNEXPECTED FATAL ERROR in worker thread " + Thread.currentThread().getName() + ": " + e.getMessage());
            e.printStackTrace(); // Log the full stack trace
            signalShutdown(); // Signal others to stop on fatal error? Optional.
        } finally {
            System.out.println("Worker thread finished: " + Thread.currentThread().getName());
        }
    } // End run()


    // --- Static Helper Methods ---
    // (getDocument, calculateCompactString, normalizeLink, generateFilenameFromUrlPath, saveHtmlDocument)
    // Ensure these are truly static or refactor if they need instance state.

    private static Path saveHtmlDocument(String url, Document doc) throws IOException, URISyntaxException, InvalidPathException {
        String filenameBase = generateFilenameFromUrlPath(url); // Gets sanitized base name
        String filename = filenameBase + ".html";

        // Directory strategy (e.g., based on host) - ensure host extraction is safe
        URI uri = new URI(url);
        String hostDirName = sanitizePathComponent(uri.getHost());
        if (hostDirName.isEmpty()) hostDirName = "_unknown_host_"; // Handle cases with no host?

        Path storageDir = BASE_STORAGE_PATH.resolve(hostDirName);
        Files.createDirectories(storageDir); // Ensure base/host_dir exists

        Path filePath = storageDir.resolve(filename);

        String fullHTML = doc.outerHtml();
        // System.out.println(Thread.currentThread().getName() + " -> Saving HTML to: " + filePath.toAbsolutePath());
        Files.writeString(filePath, fullHTML, StandardCharsets.UTF_8);
        // System.out.println(Thread.currentThread().getName() + " -> Saved HTML successfully.");
        return filePath; // Return the path where it was saved
    }

    private static String sanitizePathComponent(String input) {
        if (input == null) return "_null_";
        String sanitized = INVALID_FILENAME_CHARS.matcher(input).replaceAll("_");
        int maxLength = 100;
        // Remove leading/trailing underscores/dots that might be problematic
        sanitized = sanitized.replaceAll("^[._]+|[._]+$", "");
        if (sanitized.isEmpty()) return "_empty_"; // Handle case where only invalid chars were present
        return sanitized.length() > maxLength ? sanitized.substring(0, maxLength) : sanitized;
    }

    public static String generateFilenameFromUrlPath(String urlString) throws URISyntaxException {
        URI uri = new URI(urlString);
        String authority = uri.getHost();
        String path = uri.getPath();
        if (authority == null) { throw new URISyntaxException(urlString, "URL must have a host");}
        if (path == null || path.isEmpty() || path.equals("/")) { path = "_root"; }
        else { if (path.startsWith("/")) { path = path.substring(1); } path = path.replace("/", "_"); }
        String baseName = authority + "_" + path;
        // Apply sanitization here as well, using the shared utility
        return sanitizePathComponent(baseName); // Return base name WITHOUT extension
    }

    // --- Other static helpers ---
     private static Document getDocument(String url) { /* ... as before ... */
         try {
			Connection.Response response = Jsoup.connect(url).userAgent(MY_USER_AGENT) // Use constant
            		.timeout(5000).followRedirects(true).ignoreHttpErrors(true).execute(); // ignoreHttpErrors might be useful
			int status = response.statusCode();
			// Allow 2xx status codes only
			if(status < 200 || status >= 300) {
				 System.err.println("   Skipped NON-OK response (" + status + ") for: " + url); return null; }
			String contentType = response.contentType();
			if(contentType == null || !contentType.toLowerCase().contains("text/html")) {
				 System.err.println("   Skipped NON-HTML content (" + contentType + ") for: " + url); return null; }
            // Check for redirects before parsing (optional, Jsoup handles internally with followRedirects)
            // String finalUrl = response.url().toString();
            // if (!currentUrl.equals(finalUrl)) { /* Handle redirect if needed */ }
            return response.parse();
        } catch (Exception e) { System.err.println("   Fetch/Parse error for " + url + ": " + e.getMessage()); return null; }
     }
     private static String calculateCompactString(Document doc) { /* ... as before ... */
          if (doc == null || doc.body() == null) return null;
          try { String text = doc.body().text(); String[] list = text.split("\\s+"); StringBuilder csBuilder = new StringBuilder();
              for(String word:list) { word = word.trim(); if(word.length()>2) { char firstChar = word.charAt(0); if (Character.isLetterOrDigit(firstChar)) { csBuilder.append(firstChar);}}}
              return csBuilder.toString();
          }catch(Exception e) { System.err.println("   Error calculating compact string: " + e.getMessage()); return null; }
     }
     private static String normalizeLink(String urlString) throws URISyntaxException, MalformedURLException { /* ... as before (using URL then URI) ... */
        if (urlString == null) throw new IllegalArgumentException("URL cannot be null");
        URL url = new URL(urlString); String scheme = url.getProtocol(); String host = url.getHost(); int port = url.getPort(); String path = url.getPath();
        if (scheme == null || host == null) { throw new URISyntaxException(urlString, "URL lacks scheme or host");}
        if (path == null || path.isEmpty()) { path = "/"; } else if (!path.startsWith("/")) { path = "/" + path; }
        URI normalizedUri = new URI(scheme.toLowerCase(), null, host.toLowerCase(), port, path, null, null);
        String normalizedLink = normalizedUri.toString();
        String currentPath = normalizedUri.getPath();
        if (normalizedLink.endsWith("/") && currentPath != null && currentPath.length() > 1) { normalizedLink = normalizedLink.substring(0, normalizedLink.length() - 1); }
        return normalizedLink;
     }

} // End WebCrawler class